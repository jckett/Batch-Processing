{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Streaming Data\n",
    "Name: Joi Chu-Ketterer <br>  Date: 2/2/20<br>Course: DSC650 - Big Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these packages allow me to create the streams\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# this allows me to access the files on my system \n",
    "import os \n",
    "\n",
    "# this allows me to copy the files into a new folder\n",
    "import shutil\n",
    "\n",
    "# this allows me to make the stream/query pause before proceeding\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jckett/Jupyter Notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this checks the local directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to define the schema \n",
    "file_path = '/Users/jckett/Jupyter Notebooks/baby-names/streaming/names_00.csv'\n",
    "\n",
    "# this is so the stream knows where to pull from\n",
    "directory = '/Users/jckett/Jupyter Notebooks/baby-names/streaming'\n",
    "\n",
    "# this is the where the files are copied to, and the count is updated\n",
    "streaming_path = '/Users/jckett/Jupyter Notebooks/input_streaming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this initiates the spark session and sets the schema\n",
    "spark = SparkSession.builder.appName('FemaleCount').getOrCreate()\n",
    "static = spark.read.csv(file_path, header = True)\n",
    "dataschema = static.schema\n",
    "\n",
    "# checks schema structure\n",
    "static.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_test = static.groupBy('sex').count()\n",
    "count_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# this defines what the stream reads\n",
    "streaming = spark.readStream.schema(dataschema).csv(directory) \n",
    "\n",
    "# this defines the action to take on the files during the stream\n",
    "counts = streaming.groupBy(\"sex\").count()\n",
    "\n",
    "# this initiates the action\n",
    "streamingquery = counts.writeStream.queryName(\"counts\").format(\"memory\").outputMode(\"complete\").start()\n",
    "\n",
    "# this checks to see if the streaming has started\n",
    "print(counts.isStreaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names_36.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_22.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_23.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_37.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_09.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_21.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_35.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_34.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_20.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_08.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this selects all the files in the directory folder\n",
    "file_name = os.listdir(directory)\n",
    "\n",
    "# this displays the count after each file is copied from the directory\n",
    "# to the input_stream folder\n",
    "\n",
    "for i in range(len(file_name[1:11])):\n",
    "    \n",
    "    file = file_name[i]\n",
    "    \n",
    "    print(file)\n",
    "    src_path = os.path.join(directory,file)\n",
    "    dest_path = os.path.join(streaming_path,file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path) \n",
    "    \n",
    "    spark.sql(\"SELECT * FROM counts \\\n",
    "                WHERE SEX == 'F'\").show()\n",
    "    \n",
    "    sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Micro-Batching__\n",
    "\n",
    "Instead of continuous streaming, the files will be counted in small batches, triggered every 30 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# this defines where the batch files will get copied to\n",
    "batch_stream = '/Users/jckett/Jupyter Notebooks/batch_streaming'\n",
    "\n",
    "# similar to before, this defines what the stream reads\n",
    "batch_sc = spark.readStream.schema(dataschema).csv(batch_stream)\n",
    "batch_counts = batch_sc.groupBy(\"sex\").count()\n",
    "\n",
    "# this defines how the stream operates and the limitations\n",
    "microquery = batch_counts.writeStream.trigger(processingTime = \"30 Seconds\").queryName(\"batch_counts\").format(\"memory\").outputMode(\"complete\").start()\n",
    "\n",
    "print(microquery.isActive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names_36.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_22.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_23.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_37.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_09.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_21.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_35.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_34.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_20.csv\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this iterates through all the files in the original folder\n",
    "# copies the files one by one into the new folder and calculates \n",
    "# new counts every 30 seconds\n",
    "\n",
    "for i in range(len(file_name[1:10])):\n",
    "    \n",
    "    file = file_name[i]\n",
    "    \n",
    "    print(file)\n",
    "    src_path = os.path.join(directory,file)\n",
    "    dest_path = os.path.join(batch_stream,file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path) \n",
    "    \n",
    "    spark.sql(\"SELECT * FROM counts \\\n",
    "                WHERE SEX == 'F'\").show()\n",
    "    \n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
